{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#參考資料 https://www.kaggle.com/outrunner/use-keras-to-count-sea-lions\n",
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import keras\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from tempfile import TemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = 0.4     #scale down\n",
    "width = 100 #patch size \n",
    "filedir       = '/home/alvin/cei/notebook_home/ai_lab_image/corpus/Kaggle_Sealion_10'\n",
    "skip_loading  = True\n",
    "Tbeg_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetData(filename):\n",
    "    # read the Train and Train Dotted images\n",
    "    #image_1 = cv2.imread(\"../input/TrainDotted/\" + filename)\n",
    "    #image_2 = cv2.imread(\"../input/Train/\" + filename)\n",
    "    image_1 = cv2.imread(filedir + '/TrainDotted/' + filename)\n",
    "    image_2 = cv2.imread(filedir + '/Train/' + filename)    \n",
    "    img1 = cv2.GaussianBlur(image_1,(5,5),0)\n",
    "\n",
    "    # absolute difference between Train and Train Dotted\n",
    "    if(image_1.shape !=  image_2.shape):\n",
    "        #skip due to size not equal\n",
    "        return np.array([]),np.array([]),'error_no_2'\n",
    "    image_3 = cv2.absdiff(image_1,image_2)\n",
    "    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 50] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "    image_4 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "\n",
    "    # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "    image_6 = np.max(image_4,axis=2)\n",
    "  \n",
    "    # alvin: check blog_log\n",
    "    rmse = np.sqrt((image_3**2).mean())\n",
    "    if(rmse > 8.0):\n",
    "        #print('skip due to blob failed')\n",
    "        return np.array([]),np.array([]),'error_no_1'\n",
    "    \n",
    "    \n",
    "    # detect blobs\n",
    "    blobs = skimage.feature.blob_log(image_6, min_sigma=3, max_sigma=7, num_sigma=1, threshold=0.05)\n",
    "\n",
    "    h,w,d = image_2.shape\n",
    "\n",
    "    res=np.zeros((int((w*r)//width)+1,int((h*r)//width)+1,5), dtype='int16')\n",
    "\n",
    "    for blob in blobs:\n",
    "        # get the coordinates for each blob\n",
    "        y, x, s = blob\n",
    "        # get the color of the pixel from Train Dotted in the center of the blob\n",
    "        b,g,R = img1[int(y)][int(x)][:]\n",
    "        x1 = int((x*r)//width)\n",
    "        y1 = int((y*r)//width)\n",
    "        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "        if R > 225 and b < 25 and g < 25: # RED\n",
    "            res[x1,y1,0]+=1\n",
    "        elif R > 225 and b > 225 and g < 25: # MAGENTA\n",
    "            res[x1,y1,1]+=1\n",
    "        elif R < 75 and b < 50 and 150 < g < 200: # GREEN\n",
    "            res[x1,y1,4]+=1\n",
    "        elif R < 75 and  150 < b < 200 and g < 75: # BLUE\n",
    "            res[x1,y1,3]+=1\n",
    "        elif 60 < R < 120 and b < 50 and g < 75:  # BROWN\n",
    "            res[x1,y1,2]+=1\n",
    "\n",
    "    ma = cv2.cvtColor((1*(np.sum(image_1, axis=2)>20)).astype('uint8'), cv2.COLOR_GRAY2BGR)\n",
    "    img = cv2.resize(image_2 * ma, (int(w*r),int(h*r)))\n",
    "    h1,w1,d = img.shape\n",
    "\n",
    "    trainX = []\n",
    "    trainY = []\n",
    "\n",
    "    for i in range(int(w1//width)):\n",
    "        for j in range(int(h1//width)):\n",
    "            trainY.append(res[i,j,:])\n",
    "            trainX.append(img[j*width:j*width+width,i*width:i*width+width,:])\n",
    "\n",
    "    return np.array(trainX), np.array(trainY), 'ok'\n",
    "    #return trainX,trainY\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total traing file = 21\n"
     ]
    }
   ],
   "source": [
    "# get file list\n",
    "filelist = os.listdir(filedir + '/Train')\n",
    "filelist.sort()\n",
    "filelist = filter(lambda x: x.endswith('.jpg'), filelist)\n",
    "filelist = list(filelist)\n",
    "print('Total traing file = ' + str(len(filelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(filelist)*0.7)\n",
    "trainset = np.arange(n_train)\n",
    "testingset = np.arange(n_train,len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training vector\n",
    "final_trainX = np.array([])\n",
    "final_trainY = np.array([])\n",
    "final_testX  = np.array([])\n",
    "final_testY  = np.array([])\n",
    "\n",
    "if skip_loading == False:\n",
    "    \n",
    "    print('loading training data ...')\n",
    "    \n",
    "    trainset = np.arange(n_train)\n",
    "    for i in trainset:\n",
    "    \n",
    "        trainX, trainY,flag = GetData(filelist[i])\n",
    "        if(flag == 'ok'):\n",
    "            print('Traing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "        else:\n",
    "            print('Traing '+ str(i) + '\\t' + str(filelist[i]) + '\\t' + flag)\n",
    "            continue\n",
    "    \n",
    "        np.random.seed(1004)\n",
    "        randomize = np.arange(len(trainX))\n",
    "        np.random.shuffle(randomize)\n",
    "        trainX = trainX[randomize]\n",
    "        trainY = trainY[randomize]\n",
    "    \n",
    "        final_trainX = np.vstack([final_trainX, trainX]) if final_trainX.size else trainX\n",
    "        final_trainY = np.vstack([final_trainY, trainY]) if final_trainY.size else trainY\n",
    "    '''\n",
    "    print('\\nloading testing data')    \n",
    "    testingset = np.arange(n_train,len(filelist))\n",
    "    #testingset = np.arange(n_train,n_train+10)\n",
    "    for i in testingset:\n",
    "        testX, testY, flag = GetData(filelist[i])\n",
    "        if(testX.size):\n",
    "            print('Testing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "        else:\n",
    "            print('Tesing '+ str(i) + '\\t' + str(filelist[i]) + '\\t' + flag)\n",
    "            continue\n",
    "    \n",
    "        np.random.seed(1004)\n",
    "        randomize = np.arange(len(testX))\n",
    "        np.random.shuffle(randomize)\n",
    "        testX = testX[randomize]\n",
    "        testY = testY[randomize]\n",
    "    \n",
    "        final_testX = np.vstack([final_testX, testX]) if final_testX.size else testX\n",
    "        final_testY = np.vstack([final_testY, trainY]) if final_testY.size else trainY\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save traing/testing data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if skip_loading == False:\n",
    "    np.save('o_trainx', final_trainX)\n",
    "    np.save('o_trainy', final_trainY)\n",
    "    #np.save('o_testx', final_testX)\n",
    "    #np.save('o_testy', final_testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load traing/testing data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip_loading flag is on\n",
      "we hange trainX/trainY from 14 file\n",
      "total testing file number is 7\n"
     ]
    }
   ],
   "source": [
    "if skip_loading == True:\n",
    "    final_trainX = np.load('o_trainx.npy')\n",
    "    final_trainY = np.load('o_trainy.npy')\n",
    "    #final_testX = np.load('o_testx.npy')\n",
    "    #final_testY = np.load('o_testy.npy')\n",
    "    print('skip_loading flag is on')\n",
    "    print('we hange trainX/trainY from '+str(n_train)+' file')\n",
    "    print('total testing file number is ' + str(len(range(n_train,len(filelist)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3824, 5)\n"
     ]
    }
   ],
   "source": [
    "print(final_trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1,4,i+1)\n",
    "    plt.imshow(cv2.cvtColor(trainX[i], cv2.COLOR_BGR2RGB))\n",
    "print(trainY[:4])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if skip_loading == False:\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(width,width,3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(5, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_loading == False:\n",
    "    start_time = time.time()\n",
    "    optim = keras.optimizers.SGD(lr=1e-5, momentum=0.2)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "    model.fit(final_trainX, final_trainY, epochs=8, verbose=2)\n",
    "    end_time = time.time()\n",
    "    print('\\nspend ' + str(round(end_time-start_time,1))+'s')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if skip_loading == False:\n",
    "    start_time = time.time()\n",
    "    optim = keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "    model.fit(final_trainX, final_trainY, epochs=30, verbose=2)\n",
    "    end_time = time.time()\n",
    "    print('\\nspend ' + str(round(end_time-start_time,1))+'s')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_loading == False:\n",
    "    model.save('cei-sealion.h5')\n",
    "if skip_loading == True:\n",
    "    model = keras.models.load_model('cei-sealion.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>training data</font> evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing 0\t0.jpg\n",
      "Training set --\n",
      "    ground truth:  [ 58  12 472  41 330]\n",
      "  evaluate count:  [ 64  55 193  82 105]\n",
      "      difference:  [  6  43 279  41 225]\n",
      "            rmse:  162.500461538\n",
      "Traing 1\t1.jpg\n",
      "Training set --\n",
      "    ground truth:  [ 2 20  0 11  0]\n",
      "  evaluate count:  [40 38 99 54 40]\n",
      "      difference:  [38 18 99 43 40]\n",
      "            rmse:  54.8051092509\n",
      "Traing 2\t10.jpg\n",
      "Training set --\n",
      "    ground truth:  [4 4 7 5 0]\n",
      "  evaluate count:  [27 21 60 48 37]\n",
      "      difference:  [23 17 53 43 37]\n",
      "            rmse:  37.0\n",
      "Traing 3\t11.jpg\n",
      "Training set --\n",
      "    ground truth:  [ 3  5 36 13  0]\n",
      "  evaluate count:  [23 37 85 40 44]\n",
      "      difference:  [20 32 49 27 44]\n",
      "            rmse:  36.0277670693\n",
      "Traing 4\t12.jpg\n",
      "Training set --\n",
      "    ground truth:  [ 3  9 13  1  7]\n",
      "  evaluate count:  [15 55 51 44 17]\n",
      "      difference:  [12 46 38 43 10]\n",
      "            rmse:  33.6243959054\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#n_train = 20\n",
    "trainset     = np.arange(n_train)\n",
    "five_rmse_vec= np.array([])\n",
    "dist_vec     = np.zeros((1,5))\n",
    "for i in trainset:\n",
    "    \n",
    "    trainX, trainY, flag = GetData(filelist[i])\n",
    "    if(trainX.size):\n",
    "        print('Traing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "    else:\n",
    "        print('Traing '+ str(i) + '\\t' + str(filelist[i]) + '\\t' + flag)\n",
    "        continue\n",
    "        \n",
    "    result = model.predict(trainX)\n",
    "    ground_truth_vec = np.sum(trainY, axis=0)\n",
    "    prediction_vec   = np.sum(result*(result>0.3), axis=0).astype('int')\n",
    "    five_class_rmse  = rmse(prediction_vec,ground_truth_vec)\n",
    "    five_rmse_vec    = np.append(five_rmse_vec,five_class_rmse)\n",
    "    dist_vec        += np.abs(prediction_vec-ground_truth_vec)\n",
    "    \n",
    "    \n",
    "    print('Training set --')\n",
    "    print('    ground truth: ', ground_truth_vec)\n",
    "    print('  evaluate count: ', prediction_vec)\n",
    "    print('      difference: ', str(np.abs(prediction_vec-ground_truth_vec)))\n",
    "    print('            rmse: ', str(five_class_rmse))\n",
    "\n",
    "print('\\nfinal rmse: ',str(np.average(five_rmse_vec)))\n",
    "print('final diffence ', str(dist_vec))\n",
    "end_time = time.time()\n",
    "print('\\nspend ' + str(round(end_time-start_time,1))+'s')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>testing data</font> evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#trainset      = np.arange(n_train)\n",
    "five_rmse_vec= np.array([])\n",
    "dist_vec     = np.zeros((1,5))\n",
    "testingset = np.arange(n_train,len(filelist))\n",
    "for i in testingset:\n",
    "    \n",
    "    testX, testY, flag = GetData(filelist[i])\n",
    "    if(testX.size):\n",
    "        print('Testing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "    else:\n",
    "        print('Testing '+ str(i) + '\\t' + str(filelist[i]) + '\\t' + flag)\n",
    "        continue\n",
    "        \n",
    "    result = model.predict(testX)\n",
    "    ground_truth_vec = np.sum(testY, axis=0)\n",
    "    prediction_vec   = np.sum(result*(result>0.3), axis=0).astype('int')\n",
    "    five_class_rmse  = rmse(prediction_vec,ground_truth_vec)\n",
    "    five_rmse_vec    = np.append(five_rmse_vec,five_class_rmse)\n",
    "    dist_vec        += np.abs(prediction_vec-ground_truth_vec)\n",
    "    \n",
    "    \n",
    "    print('Testing set --')\n",
    "    print('    ground truth: ', ground_truth_vec)\n",
    "    print('  evaluate count: ', prediction_vec)\n",
    "    print('      difference: ', str(np.abs(prediction_vec-ground_truth_vec)))\n",
    "    print('            rmse: ', str(five_class_rmse))\n",
    "\n",
    "print('\\nfinal rmse: ',str(np.average(five_rmse_vec)))\n",
    "print('final diffence ', str(dist_vec))\n",
    "end_time = time.time()\n",
    "print('\\nspend ' + str(end_time-start_time)+'s')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tend_time = time.time()\n",
    "print('\\nspend ' + str(round(Tend_time-Tbeg_time,1))+'s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
