{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#參考資料 https://www.kaggle.com/outrunner/use-keras-to-count-sea-lions\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = 0.4     #scale down\n",
    "width = 100 #patch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetData(filename):\n",
    "    # read the Train and Train Dotted images\n",
    "    #image_1 = cv2.imread(\"../input/TrainDotted/\" + filename)\n",
    "    #image_2 = cv2.imread(\"../input/Train/\" + filename)\n",
    "    image_1 = cv2.imread(\"../corpus/KaggleNOAASeaLions/TrainDotted/\" + filename)\n",
    "    image_2 = cv2.imread(\"../corpus/KaggleNOAASeaLions/Train/\" + filename)    \n",
    "    img1 = cv2.GaussianBlur(image_1,(5,5),0)\n",
    "\n",
    "    # absolute difference between Train and Train Dotted\n",
    "    image_3 = cv2.absdiff(image_1,image_2)\n",
    "    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 50] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "    image_4 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "\n",
    "    # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "    image_6 = np.max(image_4,axis=2)\n",
    "\n",
    "    # detect blobs\n",
    "    blobs = skimage.feature.blob_log(image_6, min_sigma=3, max_sigma=7, num_sigma=1, threshold=0.05)\n",
    "\n",
    "    h,w,d = image_2.shape\n",
    "\n",
    "    res=np.zeros((int((w*r)//width)+1,int((h*r)//width)+1,5), dtype='int16')\n",
    "\n",
    "    for blob in blobs:\n",
    "        # get the coordinates for each blob\n",
    "        y, x, s = blob\n",
    "        # get the color of the pixel from Train Dotted in the center of the blob\n",
    "        b,g,R = img1[int(y)][int(x)][:]\n",
    "        x1 = int((x*r)//width)\n",
    "        y1 = int((y*r)//width)\n",
    "        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "        if R > 225 and b < 25 and g < 25: # RED\n",
    "            res[x1,y1,0]+=1\n",
    "        elif R > 225 and b > 225 and g < 25: # MAGENTA\n",
    "            res[x1,y1,1]+=1\n",
    "        elif R < 75 and b < 50 and 150 < g < 200: # GREEN\n",
    "            res[x1,y1,4]+=1\n",
    "        elif R < 75 and  150 < b < 200 and g < 75: # BLUE\n",
    "            res[x1,y1,3]+=1\n",
    "        elif 60 < R < 120 and b < 50 and g < 75:  # BROWN\n",
    "            res[x1,y1,2]+=1\n",
    "\n",
    "    ma = cv2.cvtColor((1*(np.sum(image_1, axis=2)>20)).astype('uint8'), cv2.COLOR_GRAY2BGR)\n",
    "    img = cv2.resize(image_2 * ma, (int(w*r),int(h*r)))\n",
    "    h1,w1,d = img.shape\n",
    "\n",
    "    trainX = []\n",
    "    trainY = []\n",
    "\n",
    "    for i in range(int(w1//width)):\n",
    "        for j in range(int(h1//width)):\n",
    "            trainY.append(res[i,j,:])\n",
    "            trainX.append(img[j*width:j*width+width,i*width:i*width+width,:])\n",
    "\n",
    "    return np.array(trainX), np.array(trainY)\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 5) [1 0 3 0 1]\n",
      "(93, 5) [1 0 5 2 2]\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = GetData(\"0.jpg\")\n",
    "\n",
    "np.random.seed(1004)\n",
    "randomize = np.arange(len(trainX))\n",
    "np.random.shuffle(randomize)\n",
    "trainX = trainX[randomize]\n",
    "trainY = trainY[randomize]\n",
    "\n",
    "n_train = int(len(trainX) * 0.7)\n",
    "testX = trainX[n_train:]\n",
    "testY = trainY[n_train:]\n",
    "trainX = trainX[:n_train]\n",
    "trainY = trainY[:n_train]\n",
    "\n",
    "print(trainY.shape, trainY[0])\n",
    "print(testY.shape, testY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3 0 1]\n",
      " [1 0 2 0 2]\n",
      " [0 0 4 0 3]\n",
      " [1 0 2 0 4]]\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1,4,i+1)\n",
    "    plt.imshow(cv2.cvtColor(trainX[i], cv2.COLOR_BGR2RGB))\n",
    "print(trainY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "fig, axes1 = plt.subplots(pic_dim,pic_dim,figsize=(6,6))\n",
    "axes1[int(i/pic_dim)][int(i%pic_dim)].set_axis_off()\n",
    "axes1[int(i/pic_dim)][int(i%pic_dim)].imshow(X3[i])\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1,4,i+1)\n",
    "    plt.imshow(cv2.cvtColor(trainX[i], cv2.COLOR_BGR2RGB))\n",
    "print(trainY[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(width,width,3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(5, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "10s - loss: 37.9761\n",
      "Epoch 2/8\n",
      "10s - loss: 1.8037\n",
      "Epoch 3/8\n",
      "11s - loss: 1.7672\n",
      "Epoch 4/8\n",
      "10s - loss: 1.7170\n",
      "Epoch 5/8\n",
      "11s - loss: 1.6729\n",
      "Epoch 6/8\n",
      "11s - loss: 1.6379\n",
      "Epoch 7/8\n",
      "10s - loss: 1.6010\n",
      "Epoch 8/8\n",
      "11s - loss: 1.5835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89e2eb1da0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = keras.optimizers.SGD(lr=1e-5, momentum=0.2)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "model.fit(trainX, trainY, epochs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10s - loss: 6.2798\n",
      "Epoch 2/30\n",
      "11s - loss: 1.3970\n",
      "Epoch 3/30\n",
      "10s - loss: 1.2052\n",
      "Epoch 4/30\n",
      "12s - loss: 1.1942\n",
      "Epoch 5/30\n",
      "11s - loss: 1.0952\n",
      "Epoch 6/30\n",
      "10s - loss: 1.0589\n",
      "Epoch 7/30\n",
      "11s - loss: 1.0555\n",
      "Epoch 8/30\n",
      "11s - loss: 0.9822\n",
      "Epoch 9/30\n",
      "10s - loss: 0.9344\n",
      "Epoch 10/30\n",
      "11s - loss: 0.8989\n",
      "Epoch 11/30\n",
      "10s - loss: 0.9633\n",
      "Epoch 12/30\n",
      "10s - loss: 0.8919\n",
      "Epoch 13/30\n",
      "11s - loss: 0.8507\n",
      "Epoch 14/30\n",
      "10s - loss: 0.7697\n",
      "Epoch 15/30\n",
      "10s - loss: 0.7636\n",
      "Epoch 16/30\n",
      "11s - loss: 0.7291\n",
      "Epoch 17/30\n",
      "10s - loss: 0.6908\n",
      "Epoch 18/30\n",
      "10s - loss: 0.7222\n",
      "Epoch 19/30\n",
      "10s - loss: 0.6132\n",
      "Epoch 20/30\n",
      "10s - loss: 0.6437\n",
      "Epoch 21/30\n",
      "11s - loss: 0.6565\n",
      "Epoch 22/30\n",
      "10s - loss: 0.5523\n",
      "Epoch 23/30\n",
      "10s - loss: 0.4716\n",
      "Epoch 24/30\n",
      "10s - loss: 0.4189\n",
      "Epoch 25/30\n",
      "10s - loss: 0.4038\n",
      "Epoch 26/30\n",
      "10s - loss: 0.3513\n",
      "Epoch 27/30\n",
      "11s - loss: 0.3405\n",
      "Epoch 28/30\n",
      "10s - loss: 0.4347\n",
      "Epoch 29/30\n",
      "10s - loss: 0.3925\n",
      "Epoch 30/30\n",
      "12s - loss: 0.3161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89e0c78a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "model.fit(trainX, trainY, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set --\n",
      "    ground truth:  [ 45   9 320  27 217]\n",
      "  evaluate count:  [ 29  25 282  42 228]\n",
      "Testing set --\n",
      "    ground truth:  [ 13   3 152  14 113]\n",
      "   predict count:  [ 12  14 115  20  98]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(trainX)\n",
    "print('Training set --')\n",
    "print('    ground truth: ', np.sum(trainY, axis=0))\n",
    "print('  evaluate count: ', np.sum(result*(result>0.3), axis=0).astype('int'))\n",
    "\n",
    "result = model.predict(testX)\n",
    "print('Testing set --')\n",
    "print('    ground truth: ', np.sum(testY, axis=0))\n",
    "print('   predict count: ', np.sum(result*(result>0.3), axis=0).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.718974330876144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gro = np.sum(testY, axis=0)\n",
    "pred= np.sum(result*(result>0.3), axis=0).astype('int')\n",
    "rmse(pred,gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
