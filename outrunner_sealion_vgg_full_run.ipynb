{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#參考資料 https://www.kaggle.com/outrunner/use-keras-to-count-sea-lions\n",
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import keras\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tempfile import TemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = 0.4     #scale down\n",
    "width = 100 #patch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetData(filename):\n",
    "    # read the Train and Train Dotted images\n",
    "    #image_1 = cv2.imread(\"../input/TrainDotted/\" + filename)\n",
    "    #image_2 = cv2.imread(\"../input/Train/\" + filename)\n",
    "    image_1 = cv2.imread(\"../corpus/KaggleNOAASeaLions/TrainDotted/\" + filename)\n",
    "    image_2 = cv2.imread(\"../corpus/KaggleNOAASeaLions/Train/\" + filename)    \n",
    "    img1 = cv2.GaussianBlur(image_1,(5,5),0)\n",
    "\n",
    "    # absolute difference between Train and Train Dotted\n",
    "    if(image_1.shape !=  image_2.shape):\n",
    "        #skip due to size not equal\n",
    "        return np.array([]),np.array([]),'error_no_2'\n",
    "    image_3 = cv2.absdiff(image_1,image_2)\n",
    "    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 50] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "    image_4 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "\n",
    "    # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "    image_6 = np.max(image_4,axis=2)\n",
    "  \n",
    "    # alvin: check blog_log\n",
    "    rmse = np.sqrt((image_3**2).mean())\n",
    "    if(rmse > 8.0):\n",
    "        #print('skip due to blob failed')\n",
    "        return np.array([]),np.array([]),'error_no_1'\n",
    "    \n",
    "    \n",
    "    # detect blobs\n",
    "    blobs = skimage.feature.blob_log(image_6, min_sigma=3, max_sigma=7, num_sigma=1, threshold=0.05)\n",
    "\n",
    "    h,w,d = image_2.shape\n",
    "\n",
    "    res=np.zeros((int((w*r)//width)+1,int((h*r)//width)+1,5), dtype='int16')\n",
    "\n",
    "    for blob in blobs:\n",
    "        # get the coordinates for each blob\n",
    "        y, x, s = blob\n",
    "        # get the color of the pixel from Train Dotted in the center of the blob\n",
    "        b,g,R = img1[int(y)][int(x)][:]\n",
    "        x1 = int((x*r)//width)\n",
    "        y1 = int((y*r)//width)\n",
    "        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "        if R > 225 and b < 25 and g < 25: # RED\n",
    "            res[x1,y1,0]+=1\n",
    "        elif R > 225 and b > 225 and g < 25: # MAGENTA\n",
    "            res[x1,y1,1]+=1\n",
    "        elif R < 75 and b < 50 and 150 < g < 200: # GREEN\n",
    "            res[x1,y1,4]+=1\n",
    "        elif R < 75 and  150 < b < 200 and g < 75: # BLUE\n",
    "            res[x1,y1,3]+=1\n",
    "        elif 60 < R < 120 and b < 50 and g < 75:  # BROWN\n",
    "            res[x1,y1,2]+=1\n",
    "\n",
    "    ma = cv2.cvtColor((1*(np.sum(image_1, axis=2)>20)).astype('uint8'), cv2.COLOR_GRAY2BGR)\n",
    "    img = cv2.resize(image_2 * ma, (int(w*r),int(h*r)))\n",
    "    h1,w1,d = img.shape\n",
    "\n",
    "    trainX = []\n",
    "    trainY = []\n",
    "\n",
    "    for i in range(int(w1//width)):\n",
    "        for j in range(int(h1//width)):\n",
    "            trainY.append(res[i,j,:])\n",
    "            trainX.append(img[j*width:j*width+width,i*width:i*width+width,:])\n",
    "\n",
    "    return np.array(trainX), np.array(trainY), 'ok'\n",
    "    #return trainX,trainY\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total traing file = 949\n"
     ]
    }
   ],
   "source": [
    "# get file list\n",
    "filelist = os.listdir(\"/home/alvin/cei/notebook_home/ai_lab_image/corpus/KaggleNOAASeaLions/Train/\")\n",
    "filelist.sort()\n",
    "print('Total traing file = ' + str(len(filelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "n_train = int(len(filelist)*0.7)\n",
    "trainset = np.arange(n_train)\n",
    "testingset = np.arange(n_train,len(filelist))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare training vector\n",
    "\n",
    "final_trainX = np.array([])\n",
    "final_trainY = np.array([])\n",
    "final_testX  = np.array([])\n",
    "final_testY  = np.array([])\n",
    "\n",
    "n_train = int(len(filelist)*0.7)\n",
    "print('loading training data ...')\n",
    "\n",
    "#n_train = 20\n",
    "trainset = np.arange(n_train)\n",
    "for i in trainset:\n",
    "    \n",
    "    trainX, trainY,flag = GetData(filelist[i])\n",
    "    if(flag == 'ok'):\n",
    "        print('Traing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "    else:\n",
    "        print('Traing '+ str(i) + '\\t' + str(filelist[i]) + '\\t' + flag)\n",
    "        continue\n",
    "    \n",
    "    np.random.seed(1004)\n",
    "    randomize = np.arange(len(trainX))\n",
    "    np.random.shuffle(randomize)\n",
    "    trainX = trainX[randomize]\n",
    "    trainY = trainY[randomize]\n",
    "    \n",
    "    final_trainX = np.vstack([final_trainX, trainX]) if final_trainX.size else trainX\n",
    "    final_trainY = np.vstack([final_trainY, trainY]) if final_trainY.size else trainY\n",
    "\"\"\"\n",
    "print('\\nloading testing data')    \n",
    "testingset = np.arange(n_train,len(filelist))\n",
    "#testingset = np.arange(n_train,n_train+10)\n",
    "for i in testingset:\n",
    "    testX, testY = GetData(filelist[i])\n",
    "    if(testX.size):\n",
    "        print('Testing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "    else:\n",
    "        print('Testing '+ str(i) + '\\t' + str(filelist[i]) + ' ==> blob failed')\n",
    "        continue\n",
    "    \n",
    "    np.random.seed(1004)\n",
    "    randomize = np.arange(len(testX))\n",
    "    np.random.shuffle(randomize)\n",
    "    testX = testX[randomize]\n",
    "    testY = testY[randomize]\n",
    "    \n",
    "    final_testX = np.vstack([final_testX, testX]) if final_testX.size else testX\n",
    "    final_testY = np.vstack([final_testY, trainY]) if final_testY.size else trainY\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save traing/testing data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('o_trainx_663', final_trainX)\n",
    "np.save('o_trainy_663', final_trainY)\n",
    "#np.save('o_testx', final_testX)\n",
    "#np.save('o_testy', final_testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load traing/testing data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_trainX = np.load('o_trainx_663.npy')\n",
    "final_trainY = np.load('o_trainy_663.npy')\n",
    "#final_testX = np.load('o_testx.npy')\n",
    "#final_testY = np.load('o_testy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172709, 5)\n"
     ]
    }
   ],
   "source": [
    "print(final_trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1,4,i+1)\n",
    "    plt.imshow(cv2.cvtColor(trainX[i], cv2.COLOR_BGR2RGB))\n",
    "print(trainY[:4])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(width,width,3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(5, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "optim = keras.optimizers.SGD(lr=1e-5, momentum=0.2)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "model.fit(final_trainX, final_trainY, epochs=8, verbose=2)\n",
    "end_time = time.time()\n",
    "print('\\nspend ' + str(end_time-start_time)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "optim = keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "model.fit(final_trainX, final_trainY, epochs=30, verbose=2)\n",
    "end_time = time.time()\n",
    "print('\\nspend ' + str(end_time-start_time)+'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>training data</font> evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = 20\n",
    "trainset     = np.arange(n_train)\n",
    "five_rmse_vec= np.array([])\n",
    "dist_vec     = np.zeros((1,5))\n",
    "for i in trainset:\n",
    "    \n",
    "    trainX, trainY = GetData(filelist[i])\n",
    "    if(trainX.size):\n",
    "        print('Traing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "    else:\n",
    "        print('Traing '+ str(i) + '\\t' + str(filelist[i]) + ' ==> blob failed')\n",
    "        continue\n",
    "        \n",
    "    result = model.predict(trainX)\n",
    "    ground_truth_vec = np.sum(trainY, axis=0)\n",
    "    prediction_vec   = np.sum(result*(result>0.3), axis=0).astype('int')\n",
    "    five_class_rmse  = rmse(prediction_vec,ground_truth_vec)\n",
    "    five_rmse_vec    = np.append(five_rmse_vec,five_class_rmse)\n",
    "    dist_vec        += np.abs(prediction_vec-ground_truth_vec)\n",
    "    \n",
    "    \n",
    "    print('Training set --')\n",
    "    print('    ground truth: ', ground_truth_vec)\n",
    "    print('  evaluate count: ', prediction_vec)\n",
    "    print('      difference: ', str(np.abs(prediction_vec-ground_truth_vec)))\n",
    "    print('            rmse: ', str(five_class_rmse))\n",
    "\n",
    "print('\\nfinal rmse: ',str(np.average(five_rmse_vec)))\n",
    "print('final diffence ', str(dist_vec))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>testing data</font> evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainset      = np.arange(n_train)\n",
    "five_rmse_vec= np.array([])\n",
    "dist_vec     = np.zeros((1,5))\n",
    "testingset   = np.arange(n_train,n_train+10)\n",
    "for i in testingset:\n",
    "    \n",
    "    testX, testY = GetData(filelist[i])\n",
    "    if(testX.size):\n",
    "        print('Testing '+ str(i) + '\\t' + str(filelist[i]))\n",
    "    else:\n",
    "        print('Testing '+ str(i) + '\\t' + str(filelist[i]) + ' ==> blob failed')\n",
    "        continue\n",
    "        \n",
    "    result = model.predict(testX)\n",
    "    ground_truth_vec = np.sum(testY, axis=0)\n",
    "    prediction_vec   = np.sum(result*(result>0.3), axis=0).astype('int')\n",
    "    five_class_rmse  = rmse(prediction_vec,ground_truth_vec)\n",
    "    five_rmse_vec    = np.append(five_rmse_vec,five_class_rmse)\n",
    "    dist_vec        += np.abs(prediction_vec-ground_truth_vec)\n",
    "    \n",
    "    \n",
    "    print('Testing set --')\n",
    "    print('    ground truth: ', ground_truth_vec)\n",
    "    print('  evaluate count: ', prediction_vec)\n",
    "    print('      difference: ', str(np.abs(prediction_vec-ground_truth_vec)))\n",
    "    print('            rmse: ', str(five_class_rmse))\n",
    "\n",
    "print('\\nfinal rmse: ',str(np.average(five_rmse_vec)))\n",
    "print('final diffence ', str(dist_vec))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
